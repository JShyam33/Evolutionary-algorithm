{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "clPF_8TpxCtO"
      },
      "source": [
        "'''\n",
        "refrences\n",
        "\n",
        "1) https://www.kdnuggets.com/2018/04/building-convolutional-neural-network-numpy-scratch.html\n",
        "\n",
        "2) https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.flatten.html\n",
        "\n",
        "3) https://towardsdatascience.com/evolving-neural-networks-b24517bb3701\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIDEKpbhbE3B"
      },
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "class Organism():\n",
        "    def __init__(self, dimensions, use_bias=True, output='softmax'):\n",
        "        self.layers = []\n",
        "        self.biases = []\n",
        "        self.use_bias = use_bias\n",
        "        self.output = self._activation(output)\n",
        "        for i in range(len(dimensions)-1):\n",
        "            shape = (dimensions[i], dimensions[i+1])\n",
        "            std = np.sqrt(2 / sum(shape))\n",
        "            layer = np.random.normal(0, std, shape)\n",
        "            bias = np.random.normal(0, std, (1,  dimensions[i+1])) * use_bias\n",
        "            self.layers.append(layer)\n",
        "            self.biases.append(bias)\n",
        "\n",
        "    def _activation(self, output):\n",
        "        if output == 'softmax':\n",
        "            return lambda X : np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1, 1)\n",
        "        if output == 'sigmoid':\n",
        "            return lambda X : (1 / (1 + np.exp(-X)))\n",
        "        if output == 'linear':\n",
        "            return lambda X : X\n",
        "\n",
        "    def predict(self, X):\n",
        "        if not X.ndim == 2:\n",
        "            raise ValueError(f'Input has {X.ndim} dimensions, expected 2')\n",
        "        if not X.shape[1] == self.layers[0].shape[0]:\n",
        "            raise ValueError(f'Input has {X.shape[1]} features, expected {self.layers[0].shape[0]}')\n",
        "        for index, (layer, bias) in enumerate(zip(self.layers, self.biases)):\n",
        "            X = X @ layer + np.ones((X.shape[0], 1)) @ bias\n",
        "            if index == len(self.layers) - 1:\n",
        "                X = self.output(X) # output activation\n",
        "            else:\n",
        "                X = np.clip(X, 0, np.inf)  # ReLU\n",
        "        return X\n",
        "    def mate(self, other, mutate=True):\n",
        "        if self.use_bias != other.use_bias:\n",
        "            raise ValueError('Both parents must use bias or not use bias')\n",
        "        if not len(self.layers) == len(other.layers):\n",
        "            raise ValueError('Both parents must have same number of layers')\n",
        "        if not all(self.layers[x].shape == other.layers[x].shape for x in range(len(self.layers))):\n",
        "            raise ValueError('Both parents must have same shape')\n",
        "\n",
        "        child = copy.deepcopy(self)\n",
        "        for i in range(len(child.layers)):\n",
        "            pass_on = np.random.rand(1, child.layers[i].shape[1]) < 0.5\n",
        "            child.layers[i] = pass_on * self.layers[i] + ~pass_on * other.layers[i]\n",
        "            child.biases[i] = pass_on * self.biases[i] + ~pass_on * other.biases[i]\n",
        "        if mutate:\n",
        "            child.mutate()\n",
        "        return child\n",
        "    def mutate(self, stdev=0.03):\n",
        "        for i in range(len(self.layers)):\n",
        "            self.layers[i] += np.random.normal(0, stdev, self.layers[i].shape)\n",
        "            if self.use_bias:\n",
        "                self.biases[i] += np.random.normal(0, stdev, self.biases[i].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoQlKjHow3Yw"
      },
      "source": [
        "class Ecosystem():\n",
        "  def __init__(self,original_f,scoring_function,population_size=100,holdout='sqrt',mating=True):\n",
        "    self.population_size = population_size\n",
        "    self.population = [original_f() for _ in range(population_size)]\n",
        "\n",
        "    self.scoring_function = scoring_function\n",
        "\n",
        "    if holdout == 'sqrt':\n",
        "      self.holdout = max(1, int(np.sqrt(population_size)))\n",
        "    elif holdout == 'log':\n",
        "      self.holdout = max(1, int(np.log(population_size)))\n",
        "    elif holdout > 0 and holdout < 1:\n",
        "      self.holdout = max(1, int(holdout * population_size))\n",
        "    else:\n",
        "      self.holdout = max(1, int(holdout))\n",
        "\n",
        "    self.mating = mating\n",
        "\n",
        "\n",
        "  def generation(self,repeats= 1,keep_best = True):\n",
        "    rewards = [np.mean([self.scoring_function(x) for _ in range(repeats)]) for x in tqdm(self.population)]\n",
        "    self.population = [self.population[x] for x in np.argsort(rewards)[::-1]]\n",
        "\n",
        "    new_population = []\n",
        "\n",
        "    for i in range(self.population_size):\n",
        "      parent_1_idx = i % self.holdout\n",
        "      if self.mating:\n",
        "        parent_2_idx = min(self.population_size - 1, int(np.random.exponential(self.holdout)))\n",
        "      else:\n",
        "        parent_2_idx = parent_1_idx\n",
        "\n",
        "      offspring = self.population[parent_1_idx].mate(self.population[parent_2_idx])\n",
        "\n",
        "      new_population.append(offspring)\n",
        "\n",
        "    self.population = new_population\n",
        "\n",
        "\n",
        "  def get_best_organism(self,include_rewards =  False):\n",
        "    rewards = [self.scoring_function(x) for x in self.population ]\n",
        "\n",
        "    if include_rewards:\n",
        "      best = np.argsort(rewards)[-1]\n",
        "      return self.population[best] , rewards[best]\n",
        "    else:\n",
        "      return self.population[np.argsort(rewards)[-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ky7QIHlNFrV"
      },
      "source": [
        "def main():\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "  organism_creator = lambda : Organism([1,16,16,16,1],output='linear',use_bias = True)\n",
        "\n",
        "  true_function = lambda x: np.sin(2 * np.pi * x)\n",
        "\n",
        "  loss_function = lambda y_true, y_pred : np.mean((y_true-y_pred)**2)\n",
        "  x = np.linspace(0,1,200)\n",
        "  def simulate_and_evalulate(organism, replicates=1):\n",
        "    X = np.random.random((replicates, 1))\n",
        "    predictions = organism.predict(X)\n",
        "    loss = loss_function(true_function(X),predictions)\n",
        "\n",
        "    return -loss\n",
        "\n",
        "  scoring_function = lambda organism: simulate_and_evalulate(organism, replicates=500)\n",
        "\n",
        "  ecosystem  = Ecosystem(organism_creator,scoring_function,population_size=100,holdout= 0.1,mating = True)\n",
        "\n",
        "\n",
        "  best_organism = [ecosystem.get_best_organism()]\n",
        "\n",
        "  generations = 201\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(generations):\n",
        "    ecosystem.generation()\n",
        "    this_generation_best = ecosystem.get_best_organism(include_rewards=True)\n",
        "    best_organism.append(this_generation_best[0])\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      print(f'{i} : {this_generation_best[1]:.2f}')\n",
        "    if i % 10 == 0 and False:\n",
        "      plt.scatter(X,best_organism[-1].predict(X.reshape(-1,1)).flatten(),label='predictions')\n",
        "\n",
        "      plt.plot(X,true_function(X),label='Target', c='k')\n",
        "\n",
        "      plt.legend()\n",
        "\n",
        "      plt.title(f'Generaion {i}; rewards = {this_generation_best[1]:.2f}')\n",
        "      plt.xlabel('input')\n",
        "      plt.ylabel('output')\n",
        "\n",
        "      plt.show()\n",
        "\n",
        "  plt.scatter(x, best_organism[-1].predict(x.reshape(-1,1)).flatten(),label='Predictions')\n",
        "  plt.plot(x,true_function(x),label='Target', c='k')\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "  plt.title(f'Generaion {i}; rewards = {this_generation_best[1]:.2f}')\n",
        "  plt.xlabel('input')\n",
        "  plt.ylabel('output')\n",
        "  plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVtELBoUEPJ"
      },
      "source": [
        "Using evolutionary approach on MNIST data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD00DbTHUDSa"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Conv2D, Dense, Dropout, MaxPooling2D, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imM3VRsKVET5"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "im_row , im_cols = (28,28)\n",
        "\n",
        "(x_train,y_train) , (x_test,y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, im_row, im_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, im_row, im_cols)\n",
        "    input_shape = (1, im_row, im_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], im_row, im_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], im_row, im_cols, 1)\n",
        "    input_shape = (im_row, im_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tulWZmRhmORB"
      },
      "source": [
        "train_data_x = []\n",
        "train_data_y = []\n",
        "for i in range(10):\n",
        "  train_data_x.append(x_train[np.argmax(y_train,axis=1) == i][0])\n",
        "  train_data_y.append(y_train[np.argmax(y_train,axis=1) == i][0])\n",
        "train_data_x = np.array(train_data_x)\n",
        "train_data_y = np.array(train_data_y)\n",
        "print(train_data_x.shape)\n",
        "print(train_data_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8eGPoqbVtAi"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGqObfqLVwrB"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5n3FbLwbXf3"
      },
      "source": [
        "!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2FIND6TbUhx"
      },
      "source": [
        "%%capture\n",
        "from tqdm import tqdm_notebook as tqdm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bmTg6KKWS7U"
      },
      "source": [
        "import sys, math\n",
        "class Organism_mnist():\n",
        "  def __init__(self,layers,output='softmax'):\n",
        "    self.layers = []\n",
        "    self.output = self._activation(output)\n",
        "\n",
        "    for layer in layers:\n",
        "      struct_layer = dict()\n",
        "      struct_layer = layer\n",
        "      struct_layer['name'] = layer['name']\n",
        "      shape = layer['shape']\n",
        "      if layer['name'] != 'Dense' and layer['name'] != 'conv2d':\n",
        "        self.layers.append(struct_layer)\n",
        "        continue\n",
        "\n",
        "\n",
        "      std = np.sqrt(2 / sum(shape))\n",
        "      layer_weights = np.random.normal(0, std, shape)\n",
        "      struct_layer['weights'] = layer_weights\n",
        "      self.layers.append(struct_layer)\n",
        "\n",
        "  def _activation(self, output):\n",
        "        if output == 'softmax':\n",
        "\n",
        "            def softmax(z):\n",
        "              z_exp = [np.exp(i) for i in z]\n",
        "              sum_z_exp = sum(z_exp)\n",
        "              return [i / sum_z_exp for i in z_exp]\n",
        "            return lambda X : softmax(X)\n",
        "        if output == 'sigmoid':\n",
        "            return lambda X : (1 / (1 + np.exp(-X)))\n",
        "        if output == 'linear':\n",
        "            return lambda X : X\n",
        "  def predict(self, x):\n",
        "    layers = self.layers\n",
        "    o = []\n",
        "    for j in x:\n",
        "\n",
        "      res = j\n",
        "      for i in range(len(self.layers)):\n",
        "        if layers[i]['name'] == 'conv2d':\n",
        "\n",
        "            j = self.conv(j,layers[i]['weights'])\n",
        "\n",
        "        elif layers[i]['name'] == 'Flatten':\n",
        "          j = j.flatten()\n",
        "\n",
        "        elif layers[i]['name'] == 'Dense':\n",
        "\n",
        "          j = j @ layers[i]['weights']\n",
        "\n",
        "        elif layers[i]['name'] == 'sigmoid':\n",
        "\n",
        "          j = 1 / (1 + np.exp(j))\n",
        "\n",
        "        elif layers[i]['name'] == 'max_pool':\n",
        "          j = self.max_pool(j)\n",
        "\n",
        "        elif layers[i]['name'] == 'softmax':\n",
        "\n",
        "          j = np.array(j,dtype=np.float128)\n",
        "\n",
        "          j = self.output(j)\n",
        "           # output activation\n",
        "\n",
        "        else:\n",
        "          j = np.clip(j, 0, np.inf)  # ReLU\n",
        "\n",
        "      o.append(j)\n",
        "    return o\n",
        "\n",
        "  def max_pool(self,img):\n",
        "    feature_maps = np.zeros((int((img.shape[0] -2 +1) / 2 ), int((img.shape[1] -2 + 1) / 2) , img.shape[2]))\n",
        "    pool_size = 2\n",
        "    for ch_num in range(img.shape[2]):\n",
        "      r2 = 0\n",
        "      for r in range(0,img.shape[0] - 2 -1 ,2):\n",
        "        c2 = 0\n",
        "        for c in range(0,img.shape[1] - 2- 1,2):\n",
        "          feature_maps[r2,c2,ch_num] = np.max(img[r:r+pool_size,c:c+pool_size])\n",
        "          c2 = c2 + 1\n",
        "        r2 = r2 + 1\n",
        "\n",
        "    return feature_maps\n",
        "\n",
        "  def conv(self,img, conv_filter):\n",
        "\n",
        "    '''if len(img.shape) > 2 or len(conv_filter.shape) > 3:\n",
        "      if img.shape[-1] != conv_filter.shape[-1]:\n",
        "        print(\"Error: Number of channels in both image and filter must match. image = \",img.shape[-1],\"convule shape = \",conv_filter.shape[-1])\n",
        "\n",
        "    if conv_filter.shape[0] != conv_filter.shape[1]: # Check if filter dimensions are equal.\n",
        "        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match. row = ',conv_filter.shape[1],\" col = \",conv_filter.shape[2])\n",
        "\n",
        "    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.\n",
        "        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')  '''\n",
        "\n",
        "\n",
        "    # An empty feature map to hold the output of convolving the filter(s) with the image.\n",
        "    feature_maps = np.zeros((img.shape[0]-conv_filter.shape[1]+1,\n",
        "                                img.shape[1]-conv_filter.shape[1]+1,\n",
        "                                 conv_filter.shape[0]))\n",
        "\n",
        "     # Convolving the image by the filter(s).\n",
        "    for n_filter in range(conv_filter.shape[0]):\n",
        "\n",
        "      curr_filter =  conv_filter[n_filter,:,:]\n",
        "      if len(img.shape) > 2:\n",
        "        conv_map = self.conv_(img[:,:,0],curr_filter)\n",
        "        for ch_num in range(1 , img.shape[-1]):\n",
        "          conv_map = conv_map + self.conv_(img[:,:,ch_num],curr_filter)\n",
        "      else:\n",
        "        conv_map = self.conv_(img, curr_filter)\n",
        "\n",
        "      feature_maps[:,:,n_filter] = conv_map # Holding feature map with the current filter.\n",
        "    return feature_maps # Returning all feature maps.\n",
        "\n",
        "  def conv_(self,img, conv_filter):\n",
        "      filter_size = conv_filter.shape[0]\n",
        "      result = np.zeros((img.shape))\n",
        "\n",
        "      #Looping through the image to apply the convolution operation.\n",
        "      for r in np.uint16(np.arange(filter_size/2,\n",
        "                            img.shape[0]-filter_size/2-2)):\n",
        "          for c in np.uint16(np.arange(filter_size/2, img.shape[1]-filter_size/2-2)):\n",
        "              #Getting the current region to get multiplied with the filter.\n",
        "             curr_region = img[r:r+filter_size, c:c+filter_size]\n",
        "             #Element-wise multipliplication between the current region and the filter.\n",
        "             curr_result = curr_region * conv_filter\n",
        "             conv_sum = np.sum(curr_result) #Summing the result of multiplication.\n",
        "             result[r, c] = conv_sum #Saving the summation in the convolution layer feature map.\n",
        "\n",
        "      #Clipping the outliers of the result matrix.\n",
        "\n",
        "      final_result = result[np.uint16(filter_size/2):result.shape[0]-np.uint16(filter_size/2),\n",
        "                          np.uint16(filter_size/2):result.shape[1]-np.uint16(filter_size/2)]\n",
        "      final_result  = np.array(final_result)\n",
        "      final_result = np.reshape(final_result,(final_result.shape[0],final_result.shape[1]))\n",
        "      return final_result\n",
        "\n",
        "  def mate(self, other, mutate=True):\n",
        "\n",
        "        child = copy.deepcopy(self)\n",
        "        for i in range(len(child.layers)):\n",
        "          if self.layers[i]['name'] != 'Dense' and self.layers[i]['name'] != 'conv2d':\n",
        "            continue\n",
        "          pass_on = np.random.rand(1, child.layers[i]['weights'].shape[1]) < 0.5\n",
        "          child.layers[i]['weights'] = pass_on * self.layers[i]['weights'] + ~pass_on * other.layers[i]['weights']\n",
        "        if mutate:\n",
        "            child.mutate()\n",
        "        return child\n",
        "  def mutate(self, stdev=0.03):\n",
        "    for i in range(len(self.layers)):\n",
        "      if self.layers[i]['name'] != 'Dense' and self.layers[i]['name'] != 'conv2d':\n",
        "        continue\n",
        "      self.layers[i]['weights'] += np.random.normal(0, stdev, self.layers[i]['weights'].shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkicjm2oJyXw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8qdD1e267ws"
      },
      "source": [
        "np.arange(24,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNcvae3ilfsI"
      },
      "source": [
        "l1_filter = np.array([[[-1,0,1],\n",
        "                                  [-1,0,1],\n",
        "                                  [-1,0,1]]])\n",
        "l1_filter = np.reshape(l1_filter,(3,3,1))\n",
        "\n",
        "\n",
        "\n",
        "network = [\n",
        "           {\n",
        "              'name':'conv2d',\n",
        "              'shape':(12,3,3),\n",
        "\n",
        "          },\n",
        "          {\n",
        "              'name':'relu',\n",
        "              'shape':()\n",
        "          },\n",
        "          {\n",
        "              'name':'max_pool',\n",
        "              'shape':()\n",
        "          },\n",
        "          {\n",
        "              'name':'conv2d',\n",
        "              'shape':(24,3,3),\n",
        "\n",
        "          },\n",
        "          {\n",
        "              'name':'relu',\n",
        "              'shape':()\n",
        "          },\n",
        "          {\n",
        "              'name':'max_pool',\n",
        "              'shape':()\n",
        "          },\n",
        "          {\n",
        "              'name':'Flatten',\n",
        "              'shape':()\n",
        "          },\n",
        "          {\n",
        "              'name':'Dense',\n",
        "              'shape':(384,128)\n",
        "          },\n",
        "          {\n",
        "              'name':'relu',\n",
        "              'shape':()\n",
        "          },\n",
        "          {\n",
        "              'name':'Dense',\n",
        "              'shape':(128,10)\n",
        "          },\n",
        "          {\n",
        "              'name' : 'softmax',\n",
        "              'shape':()\n",
        "          }\n",
        "]\n",
        "\n",
        "organism_creator = lambda : Organism_mnist(network,output='softmax')\n",
        "fitness_function = lambda y_true, y_estimate : (accuracy_score(np.argmax(y_true,axis=1),np.argmax(y_estimate, axis=1)))\n",
        "\n",
        "def simulate_and_evaluate(organism, indices):\n",
        "    \"\"\"\n",
        "    Predict the probabilities of each class and return the fitness\n",
        "    Indices is the list of indices to use in evaluation\n",
        "    \"\"\"\n",
        "    predictions = organism.predict(indices)\n",
        "\n",
        "    return fitness_function(train_data_y, predictions)\n",
        "scoring_function = lambda organism : simulate_and_evaluate(organism, indices=train_data_x)\n",
        "ecosystem = Ecosystem(organism_creator, scoring_function, population_size=50, holdout=0.1, mating=True)\n",
        "generations = 50\n",
        "for i in tqdm(range(generations)):\n",
        "    ecosystem.generation()\n",
        "    this_generation_best = ecosystem.get_best_organism(include_rewards=True)\n",
        "    if i % 10 == 0:\n",
        "      print(f'{i} : {this_generation_best[1]:.2f}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Aq_MqSJ7sq"
      },
      "source": [
        "26/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbC7Rz4mA9Oh"
      },
      "source": [
        "print(np.argmax(train_data_y,axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}